import requests
from bs4 import BeautifulSoup

BASE_URL = "https://www.convocatoriasdetrabajo.com/ofertas-de-empleo-en-INGENIERIA-DE-SISTEMAS-18.html"

def scrape_page(url):
    """Extrae todas las convocatorias de una sola pÃ¡gina"""
    resp = requests.get(url)
    resp.encoding = "utf-8"
    soup = BeautifulSoup(resp.text, "html.parser")

    convocatorias = []
    for article in soup.find_all("article", class_="convocatoria"):
        # TÃ­tulo + enlace principal
        titulo_tag = article.find("h4").find("a")
        titulo = titulo_tag.get_text(strip=True) if titulo_tag else None
        link = titulo_tag["href"] if titulo_tag else None

        # Requisitos
        requisito_tag = article.find("i", class_="icon-grado")
        requisito = requisito_tag.find_next("span").get_text(strip=True) if requisito_tag else None

        # Lugar, sueldo, fecha
        lugar, sueldo, fecha = None, None, None
        grupo = article.find("li", class_="convocatoria_group")
        if grupo:
            items = grupo.find_all("span")
            if len(items) >= 3:
                lugar, sueldo, fecha = [x.get_text(strip=True) for x in items[:3]]

        # BotÃ³n "VER CONVOCATORIA"
        ver_tag = article.find("a", class_="enlace1")
        ver_link = ver_tag["href"] if ver_tag else None

        convocatorias.append({
            "titulo": titulo,
            "link": link,
            "requisito": requisito,
            "lugar": lugar,
            "sueldo": sueldo,
            "fecha": fecha,
            "ver_convocatoria": ver_link
        })

    return convocatorias

def scrape_all():
    """Recorre todas las pÃ¡ginas hasta que no encuentre mÃ¡s convocatorias"""
    all_convocatorias = []

    # âœ… PÃ¡gina base (sin parÃ¡metros)
    print(f"\nğŸŒ Scrapeando pÃ¡gina 1: {BASE_URL}")
    convocatorias = scrape_page(BASE_URL)
    all_convocatorias.extend(convocatorias)

    # âœ… PÃ¡ginas siguientes con ?page=N
    page = 2
    while True:
        url = f"{BASE_URL}?page={page}&sort=1-fechapublicacion"
        print(f"\nğŸŒ Scrapeando pÃ¡gina {page}: {url}")
        convocatorias = scrape_page(url)

        if not convocatorias:
            print("âœ… No hay mÃ¡s convocatorias. Fin del scraping.")
            break

        all_convocatorias.extend(convocatorias)
        page += 1

    return all_convocatorias

if __name__ == "__main__":
    resultados = scrape_all()

    print(f"\nğŸ“Š Total convocatorias recolectadas: {len(resultados)}\n")

    for i, r in enumerate(resultados, start=1):  # ğŸ‘ˆ arranca desde 1
        print(f"ğŸ”¹ Convocatoria {i}")
        print(f"   ğŸ¢ TÃ­tulo: {r['titulo']}")
        print(f"   ğŸ”— Link: {r['link']}")
        print(f"   ğŸ“ Requisito: {r['requisito']}")
        print(f"   ğŸ“ Lugar: {r['lugar']}")
        print(f"   ğŸ’° Sueldo: {r['sueldo']}")
        print(f"   ğŸ“… Fecha: {r['fecha']}")
        print(f"   ğŸ“„ Ver convocatoria: {r['ver_convocatoria']}")
        print("-" * 80)
